---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am now pursuing my Ph.D. career in *Artificial Intelligence* at the College of Computer Science and Technology, *Zhejiang University*, China. <!-- , supervised by Prof. [Chao Wu](https://wuchaozju.github.io/).  --> Before that, I received my bachelor's degree in *Engineering* from Zhejiang University (ZJU); meanwhile, I obtained an *honorary undergraduate degree* from Chu Kochen Honors College of ZJU. 

My main research interests lie in *__i) optimization, generalization, and personalization__* of deep learning models, especially under *distributed/federated/collaborative* setups, which are generally empowered by deep learning phenomena and mechanistic interpretability;  *__ii) trustworthy and responsible AI__* by understanding and improving foundation models (e.g., LLM, MLLM, ViT, and DiT) from *__model parameter perspective__*, i.e., model *fusion, editing, pruning, stitching, and generation*.
<!-- I am honored to work with Prof. [Tao Lin](https://lins-lab.github.io/) at Westlake University/EPFL. I was a research intern at Ant Group and Zhejiang Lab. -->

<span style="color: red;">I am on the job market now and will be graduated in the 2025 summer. I am open to both academic and industrial positions! Please contact me if you have matched positions.</span>

## Contact
Email: zexi.li\[at\]zju.edu.cn / tomleeze\[at\]gmail.com

<!--
## Research Interests
* **Collaborative Deep Learning**
  * *__Collaborative foundation models__*: LLM agents collaborated with humans, the Web, and each other; collaborative finetuning foundation models (LLMs, diffusion models, etc.).
  * *__Federated deep Learning__*: algorithm design in terms of *generalization*, *personalization*, *robustness*, and *efficiency* & *training dynamics* understanding.
  * *__Edge-cloud collaborative__* & *domain-transferred* machine learning: *real-world applications under constrained resources* (efficiency, data availability, etc.).
  * *__Trustworthy__* perspectives of machine learning: *privacy, robustness, fairness, reliability, and interpretability*.
  * *__Socio-technical issues__* brought by *big data* and *machine learning*.

* **Mechanistic Understanding of Deep Learning**
  * *__Behind mechanisms of collaborative deep learning__*: *model fusion*, *permutation invariance*, and *linear mode connectivity*.
  * *__Generalization__*: initialization, weight decay regularization, federated training, etc.
  * *__Deep learning phenomena__*: neural collapse, grokking, neural scaling law, etc.
  * Understanding and improving *__LLMs__*.-->

## Selected Publications
- [**Preprint**] [Text-to-Model: Text-Conditioned Neural Network Diffusion for Train-Once-for-All Personalization](https://arxiv.org/pdf/2405.14132)  
  **Zexi Li\***, Lingzhi Gao\*, and Chao Wu\#  
- [**Preprint**] [WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models](https://arxiv.org/pdf/2405.14768)  
  Peng Wang\*, **Zexi Li\***, Ningyu Zhang\#, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen\#
- [**ICML 2023**] [Revisiting Weighted Aggregation in Federated Learning with Neural Networks](https://proceedings.mlr.press/v202/li23s.html)  
  **Zexi Li**, Tao Lin\#, Xinyi Shang, and Chao Wu\#  
- [**Patterns, Cell Press**] [Can We Share Models If Sharing Data Is Not an Option?](https://www.cell.com/patterns/fulltext/S2666-3899(22)00228-8#%20)  
  **Zexi Li**, Feng Mao\#, and Chao Wu\#
- [**ICCV 2023**] [No Fear of Classifier Biases: Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.pdf)  
  **Zexi Li**, Xinyi Shang, Rui He, Tao Lin\#, and Chao Wu\#  
- [**ACM SIGIR 2023**] [Edge-cloud Collaborative Learning with Federated and Centralized Features](https://dl.acm.org/doi/abs/10.1145/3539618.3591976)  
  **Zexi Li\***, Qunwei Li\*, Yi Zhou, Wenliang Zhong\#, Guannan Zhang, and Chao Wu\#  
- [**IEEE Transactions on Big Data**] [Towards Effective Clustered Federated Learning: A Peer-to-peer Framework with Adaptive Neighbor Matching](https://arxiv.org/pdf/2203.12285.pdf)  
  **Zexi Li**, Jiaxun Lu, Shuang Luo, Didi Zhu, Yunfeng Shao, Yinchuan Li, Zhimeng Zhang, Yongheng Wang\#, and Chao Wu\#  

## Recent News
* **\[2024.07\]** I am happy to share our two new preprint papers: i) Generative AI goes through text-to-image to text-to-video, and we discover whether it can generate model parameters from language instructions-- i.e., text-to-model generation. Here, we present [Tina](https://arxiv.org/pdf/2405.14132), a text-to-model generative DiT, which can generate personalized model parameters directly from users' text prompts. ii) We present [WISE](https://arxiv.org/pdf/2405.14768), a model editor for large language models' lifelong model editing. WISE simultaneously reaches high performances in reliability, locality, and generalization.
* **\[2024.05\]** Two papers are accepted by KDD 2024, and one paper is accepted by ICML 2024. 
* **\[2023.11\]** I am presented with *Guoqiang Scholarship of Zhejiang University* (Top 0.5%) and *First Prize of Chunxiao Scholarship of BEST-MBA* (Top 3%) by Zhejiang University.
* **\[2023.07\]** Two papers are accepted by _International Conference on Computer Vision (**ICCV 2023**)_! One is about federated learning and the other is about domain adaptation. Many thanks to my coauthors!
* **\[2023.06\]** We will have an oral presentation of our paper [FedCNI](https://arxiv.org/abs/2304.02892) at **ICME 2023** on July 11th.
* **\[2023.04\]** Our paper ["Revisiting Weighted Aggregation in Federated Learning with Neural Networks"](https://arxiv.org/abs/2302.10911) is accepted by _The Fortieth International Conference on Machine Learning (**ICML 2023**)_! Many thanks to my coauthors!
* **\[2023.04\]** Our paper "Edge-cloud Collaborative Learning with Federated and Centralized Features" is accepted by _The 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (**SIGIR 2023**)_! Thanks a lot to Ant Group's coauthors!
* **\[2023.03\]** Our paper "Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients" is accepted by _IEEE International Conference on Multimedia and Expo 2023 (**ICME 2023**)_! Congratulations to me and Chenrui!
* **\[2023.03\]** I have joined the **BEST-MBA** (**B**usiness, **E**ngineering, **S**cience, and **T**echnology based **MBA** for on-campus postgradutes) program of _School of Management, Zhejiang University_.
<!--* **\[2022.11\]** Our paper ["Towards Effective Clustered Federated Learning: A Peer-to-peer Framework with Adaptive Neighbor Matching"](https://www.computer.org/csdl/journal/bd/5555/01/09954190/1Inoq0EldXG)\[[arxiv](https://arxiv.org/pdf/2203.12285.pdf)\] is online now.
* **\[2022.11\]** Our paper ["Can we share models if sharing data is not an option?"](https://www.cell.com/patterns/fulltext/S2666-3899(22)00228-8#%20) is online now.
* **\[2022.11\]** Our paper "Towards Effective Clustered Federated Learning: A Peer-to-peer Framework with Adaptive Neighbor Matching" has been accepted by _IEEE Transactions on Big Data_! This paper had been through a dark time in the last year, and the acceptance means a lot to me. Congratulations to myself!
* **\[2022.10\]** I have passed *the Mid-term Assessment of Doctoral Program*.
* **\[2022.10\]** I am presented with *Outstanding Postgraduate Student Award* on 2021-2022 by Zhejiang University.
* **\[2022.09\]** Our new perspective paper "Can we share models if sharing data is not an option?" is accepted by _Patterns, Cell Press_. _Patterns_ is a child-journal about _data science_ of Cell Press, and it will have a first strong impact factor in 2023.-->

## Academic Service
* Invited Reviewers: TKDE, AISTATS 2024, CVPR 2024, ICML 2024.

<!-- Help for Review: ICLR2023, KDD2023, NeurIPS2022, AAAI2022. -->
